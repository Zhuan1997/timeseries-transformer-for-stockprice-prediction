{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5440695d-5ce7-4e8e-a293-554829ae3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TimeSeriesTransformerForPrediction\n",
    "from transformers import TimeSeriesTransformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bcd636b-ffee-476f-b8e1-7cba902588e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformerConfig {\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"cardinality\": [\n",
       "    0\n",
       "  ],\n",
       "  \"context_length\": 30,\n",
       "  \"d_model\": 64,\n",
       "  \"decoder_attention_heads\": 2,\n",
       "  \"decoder_ffn_dim\": 32,\n",
       "  \"decoder_layerdrop\": 0.1,\n",
       "  \"decoder_layers\": 2,\n",
       "  \"distribution_output\": \"student_t\",\n",
       "  \"dropout\": 0.1,\n",
       "  \"embedding_dimension\": [\n",
       "    0\n",
       "  ],\n",
       "  \"encoder_attention_heads\": 2,\n",
       "  \"encoder_ffn_dim\": 32,\n",
       "  \"encoder_layerdrop\": 0.1,\n",
       "  \"encoder_layers\": 2,\n",
       "  \"feature_size\": 27,\n",
       "  \"init_std\": 0.02,\n",
       "  \"input_size\": 4,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"lags_sequence\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4\n",
       "  ],\n",
       "  \"loss\": \"nll\",\n",
       "  \"model_type\": \"time_series_transformer\",\n",
       "  \"num_dynamic_real_features\": 0,\n",
       "  \"num_parallel_samples\": 100,\n",
       "  \"num_static_categorical_features\": 0,\n",
       "  \"num_static_real_features\": 0,\n",
       "  \"num_time_features\": 3,\n",
       "  \"prediction_length\": 10,\n",
       "  \"scaling\": \"mean\",\n",
       "  \"transformers_version\": \"4.45.2\",\n",
       "  \"use_cache\": true\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing a Time Series Transformer configuration with 10 time steps for prediction\n",
    "configuration = TimeSeriesTransformerConfig(prediction_length=10,\n",
    "                                           context_length=30,\n",
    "                                           distribution_output='student_t',\n",
    "                                           input_size=4,\n",
    "                                           loss = 'nll',\n",
    "                                           \n",
    "                                           lags_sequence=[1,2,3,4],\n",
    "                                           num_time_features=3,\n",
    "                                           cardinality=None\n",
    "                                            )\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = TimeSeriesTransformerForPrediction(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93877f53-7c80-4ca3-9b58-b0785ec8e150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path = 'best_model.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c996e10a-9d0b-4143-87e0-7f7ba784e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_time_features_test = torch.load('test_past_time_features_tensor.pt')\n",
    "future_time_features_test=torch.load('test_future_time_features_tensor.pt')\n",
    "past_values_tensors_test=torch.load('test_past_value_tensor.pt')\n",
    "future_values_tensors_test=torch.load('test_future_value_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a4faf5-2d2f-4db0-a10c-cc1680eecd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([38949, 34, 3]),\n",
       " torch.Size([38949, 10, 3]),\n",
       " torch.Size([38949, 34, 4]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_time_features_test.shape,future_time_features_test.shape,past_values_tensors_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98be114-acb5-4d20-8b71-1ecd65062e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38949, 34, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a past_observed_mask tensor with shape [42844, 30,4], all elements equal to 1\n",
    "past_observed_mask_tensor = torch.ones((38949, 34,4), dtype=torch.float)\n",
    "\n",
    "# Check the shape\n",
    "past_observed_mask_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87cc6898-872b-4d7a-bb92-fe08ac0898cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "batch_size = 1000\n",
    "\n",
    "# Create a DataLoader to handle mini-batches\n",
    "test_dataset = TensorDataset(past_values_tensors_test, past_time_features_test, future_values_tensors_test, future_time_features_test,past_observed_mask_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961a8bd9-d90b-49ed-a10c-abe33f395d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction...\n",
      "Processed batch 1/39 (2.56%)\n",
      "Processed batch 2/39 (5.13%)\n",
      "Processed batch 3/39 (7.69%)\n",
      "Processed batch 4/39 (10.26%)\n",
      "Processed batch 5/39 (12.82%)\n",
      "Processed batch 6/39 (15.38%)\n",
      "Processed batch 7/39 (17.95%)\n",
      "Processed batch 8/39 (20.51%)\n",
      "Processed batch 9/39 (23.08%)\n",
      "Processed batch 10/39 (25.64%)\n",
      "Processed batch 11/39 (28.21%)\n",
      "Processed batch 12/39 (30.77%)\n",
      "Processed batch 13/39 (33.33%)\n",
      "Processed batch 14/39 (35.90%)\n",
      "Processed batch 15/39 (38.46%)\n",
      "Processed batch 16/39 (41.03%)\n",
      "Processed batch 17/39 (43.59%)\n",
      "Processed batch 18/39 (46.15%)\n",
      "Processed batch 19/39 (48.72%)\n",
      "Processed batch 20/39 (51.28%)\n",
      "Processed batch 21/39 (53.85%)\n",
      "Processed batch 22/39 (56.41%)\n",
      "Processed batch 23/39 (58.97%)\n",
      "Processed batch 24/39 (61.54%)\n",
      "Processed batch 25/39 (64.10%)\n",
      "Processed batch 26/39 (66.67%)\n",
      "Processed batch 27/39 (69.23%)\n",
      "Processed batch 28/39 (71.79%)\n",
      "Processed batch 29/39 (74.36%)\n",
      "Processed batch 30/39 (76.92%)\n",
      "Processed batch 31/39 (79.49%)\n",
      "Processed batch 32/39 (82.05%)\n",
      "Processed batch 33/39 (84.62%)\n",
      "Processed batch 34/39 (87.18%)\n",
      "Processed batch 35/39 (89.74%)\n",
      "Processed batch 36/39 (92.31%)\n",
      "Processed batch 37/39 (94.87%)\n",
      "Processed batch 38/39 (97.44%)\n",
      "Processed batch 39/39 (100.00%)\n",
      "Prediction complete!\n"
     ]
    }
   ],
   "source": [
    "# Total number of batches\n",
    "total_batches = len(test_loader)\n",
    "\n",
    "# Generate predictions in mini-batches\n",
    "all_mean_predictions = []\n",
    "\n",
    "print(\"Starting prediction...\")\n",
    "\n",
    "for batch_idx, batch in enumerate(test_loader):\n",
    "    # Unpack the batch\n",
    "    batch_past_values, batch_past_time_features, batch_future_values, batch_future_time_features, batch_past_observed_mask = batch\n",
    "    \n",
    "    # Model prediction\n",
    "    outputs = model.generate(\n",
    "        past_values=batch_past_values,\n",
    "        past_time_features=batch_past_time_features,\n",
    "        future_time_features=batch_future_time_features,\n",
    "        past_observed_mask=batch_past_observed_mask\n",
    "    )\n",
    "    \n",
    "    # Compute the mean prediction\n",
    "    mean_prediction = outputs.sequences.mean(dim=1)\n",
    "    \n",
    "    # Collect predictions\n",
    "    all_mean_predictions.append(mean_prediction)\n",
    "    \n",
    "    # Print progress for every 10th batch\n",
    "    print(f\"Processed batch {batch_idx+1}/{total_batches} ({(batch_idx+1)/total_batches*100:.2f}%)\")\n",
    "\n",
    "print(\"Prediction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eca0dcf-146e-45a3-a1bf-110909395284",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mean_predictions = torch.cat(all_mean_predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ede587-0c23-4e5c-832d-5a28e382c67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7086e+00,  1.6352e+01,  1.6659e+01, -2.2436e-01],\n",
       "         [ 1.1016e+01,  6.7102e+01,  4.6715e+01,  1.8072e+00],\n",
       "         [ 3.7967e+01,  3.0463e+01, -1.0439e+01,  1.2513e+00],\n",
       "         ...,\n",
       "         [ 4.6800e+01, -3.6752e+01, -3.4721e-01,  2.0966e+00],\n",
       "         [ 5.6351e+01, -1.8228e+01, -4.8661e+01, -2.0502e-01],\n",
       "         [ 5.1710e+01, -1.9051e+01, -2.1022e+01,  6.4342e-01]],\n",
       "\n",
       "        [[-1.4895e+00,  1.5356e+01,  2.6123e+01,  2.3519e+00],\n",
       "         [ 1.6966e+01,  7.4463e+00, -2.7842e+00,  1.1521e-01],\n",
       "         [ 1.1746e+01,  1.1001e+01, -4.5426e+00, -2.3459e+00],\n",
       "         ...,\n",
       "         [ 1.5824e+00, -4.6295e+00,  1.3863e+01, -1.9528e+00],\n",
       "         [ 1.8406e+01,  1.2853e+01,  3.2364e+01, -1.7912e+00],\n",
       "         [ 6.6342e+00,  1.0064e+01, -2.5500e+00, -4.3675e+00]],\n",
       "\n",
       "        [[ 1.0777e+01,  2.9949e+00, -1.2926e+01, -3.3928e-01],\n",
       "         [-1.3940e+01,  3.5890e+01,  5.0964e+01,  3.7098e+00],\n",
       "         [ 4.9544e+00,  9.4251e+00,  1.1573e+01,  1.7193e+00],\n",
       "         ...,\n",
       "         [ 1.0166e+01,  2.4751e+01, -1.1452e+01, -8.0291e-02],\n",
       "         [ 1.4698e+01,  3.7067e+00,  3.4283e+01, -1.3120e+00],\n",
       "         [ 5.6895e+00,  1.0390e+01,  1.7195e+01,  1.1772e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.2826e+01,  2.1582e+01,  2.0555e+01, -4.6337e-02],\n",
       "         [ 5.9384e+01,  1.4516e+01,  1.0643e+01,  4.4136e-02],\n",
       "         [ 1.5879e+01, -5.8507e+00,  4.8060e+00, -1.4559e-01],\n",
       "         ...,\n",
       "         [-5.3699e+00,  4.5491e+01,  5.9483e+00,  1.2997e-01],\n",
       "         [-2.1067e+01,  1.3911e+01,  2.1252e+01, -8.7787e-02],\n",
       "         [ 8.9403e+00,  5.5040e+01, -1.2310e+00,  7.4701e-02]],\n",
       "\n",
       "        [[-2.4527e+01,  4.8091e+01,  2.3285e+01,  6.7279e-02],\n",
       "         [ 3.4485e+01, -2.4531e+00,  8.7108e+00, -5.0689e-02],\n",
       "         [ 2.3116e+01,  1.9239e+01, -7.5168e+01,  2.9977e-02],\n",
       "         ...,\n",
       "         [ 1.7297e+01,  3.0099e+00, -2.0182e+01,  4.5779e-02],\n",
       "         [ 7.9155e+00,  1.2073e+01,  3.3602e+01, -8.1025e-02],\n",
       "         [ 1.5666e+01, -1.2278e+00, -2.1805e+01, -1.4021e-02]],\n",
       "\n",
       "        [[-8.7357e+00,  3.4567e+01,  3.1083e+01,  6.7208e+00],\n",
       "         [ 8.0875e+01,  3.6421e+01, -2.9844e+00, -4.2829e+00],\n",
       "         [ 3.2875e+01,  3.0604e+01,  5.1074e+01,  2.6568e+00],\n",
       "         ...,\n",
       "         [ 2.4919e+01, -1.6499e+01, -3.2553e+01,  4.2663e+00],\n",
       "         [ 5.3371e+01,  1.5438e+01,  2.3759e+01,  6.8894e+00],\n",
       "         [ 3.3934e+01,  1.3546e+01, -5.1418e+01,  1.4618e+00]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mean_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "151c9dd2-d227-4876-aea8-eab2fe69afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_mean_predictions, 'prediction_value.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6c207-0b11-4e3d-9e2e-faf680ed5e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
